{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entity Extraction from IBM's Quaterly Earning Transcript call using Granite-8B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook works with two approaches to extract the entities from the transcript. The first approach is defining the entities in the prompt directly along with its description. In the second approach, we are defining the entities in a class and then converting it into pydantic function. This is then passed along with the prompt to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The model used in this notebook is IBM's Granite-8b.\n",
    "Authors: Anupam Chakraborty, Amogh Ranavade, Madhu Kanukula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/ibm-granite-community/utils.git \\\n",
    "    langchain-community \\\n",
    "    langchain-docling \\\n",
    "    langchain-core \\\n",
    "    langchain-huggingface \\\n",
    "    langchain_community \\\n",
    "    langchain \\\n",
    "    pydantic \\\n",
    "    replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_community.llms import Replicate\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "model = Replicate(\n",
    "    model=model_path,\n",
    "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Entity Extraction by defining entities in the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach is straightforward and involves explicitly defining the entities within the prompt itself. In this method, we specify the entities to be extracted along with their descriptions directly in the prompt. This includes:  \n",
    "\n",
    "<u>**Entity Definitions:**</u> Each entity, such as company name, name of the CEO are clearly outlined with a concise description of what it represents.  \n",
    "\n",
    "<u>**Prompt Structure:**</u> The prompt is structured to guide the LLM in understanding exactly what information is needed. By providing detailed instructions, we aim to ensure that the model focuses on extracting only the relevant data.  \n",
    "\n",
    "<u>**Output Format:**</u> The output is required to be in JSON format, which enforces a consistent structure for the extracted data. If any entity is not found, the model is instructed to return \"Data not available,\" preventing ambiguity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the transcript PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcript is taken from -> https://www.ibm.com/investor/att/pdf/IBM-3Q23-Earnings-Prepared-Remarks.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are loading the PDF from this link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from docling.chunking import BaseChunk, HybridChunker\n",
    "from docling.datamodel.document import DoclingDocument\n",
    "from langchain_docling.loader import BaseMetaExtractor, DoclingLoader, ExportType\n",
    "\n",
    "EMBED_MODEL_ID = \"ibm-granite/granite-embedding-125m-english\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "\n",
    "class MetaExtractor(BaseMetaExtractor):\n",
    "    \"\"\"Add a unique doc_id to each document's metadata\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.doc_id = 0\n",
    "    def extract_chunk_meta(self, file_path: str, chunk: BaseChunk) -> dict[str, typing.Any]:\n",
    "        self.doc_id = self.doc_id + 1\n",
    "        return {\n",
    "            \"source\": file_path,\n",
    "            \"doc_id\": self.doc_id,\n",
    "        }\n",
    "    def extract_dl_doc_meta(\n",
    "        self, file_path: str, dl_doc: DoclingDocument\n",
    "    ) -> dict[str, typing.Any]:\n",
    "        self.doc_id = self.doc_id + 1\n",
    "        return {\n",
    "            \"source\": file_path,\n",
    "            \"doc_id\": self.doc_id,\n",
    "        }\n",
    "\n",
    "def extract_text_from_pages(pdf_path):\n",
    "    loader = DoclingLoader(\n",
    "        file_path=pdf_path,\n",
    "        export_type=EXPORT_TYPE,\n",
    "        chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    "        meta_extractor=MetaExtractor()\n",
    "    )\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ibm.com/investor/att/pdf/IBM-3Q23-Earnings-Prepared-Remarks.pdf\"\n",
    "\n",
    "transcript_content = extract_text_from_pages(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the entities that needs to be fetched are defined in the prompt itself along with the entity's description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_prompt = tokenizer.apply_chat_template(\n",
    "    conversation=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"\\\n",
    "- You are AI Entity Extractor. You help extracting entities from the given transcript documents.\n",
    "- Analyze the transcript documents and extract the following entities:\n",
    "\n",
    "1) `company_name` : This is the name of the company for which the transcript is given.\n",
    "2) `pre_tax_profit_percentage`: This is the operating pre-tax profit in percentage.\n",
    "3) `pre_tax_profit_number`: This is the operating pre-tax profit in numbers.\n",
    "4) `total_revenue_transaction_processing`: This is the total revenue growth for Transaction Processing sector in percentage.\n",
    "5) `total_revenue_data_ai`: This is the total revenue growth for Data and AI sector in percentage.\n",
    "6) `total_revenue_security`: This is the total revenue growth/decline for security sector in percentage.\n",
    "7) `total_revenue_automation`: This is total revenue growth/decline for automation sector in percentage.\n",
    "\n",
    "- Your output should strictly be in a json format.\n",
    "- If any entity is not found, your output should be `data not available`. Do not make up your own entities if it is not present\n",
    "- Only strictly do what is asked to you. Do not give any explanations to your output.\n",
    "\"\"\",\n",
    "    }],\n",
    "    documents=[{\n",
    "        \"doc_id\": doc.metadata[\"doc_id\"],\n",
    "        \"text\": doc.page_content,\n",
    "    } for doc in transcript_content],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the model to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(transcript_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "entities_transcript = json.loads(response)\n",
    "entities_transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Pydantic Class-Based Entity Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach takes advantage of object-oriented programming principles by defining entities within a class structure. This method involves several key steps:  \n",
    "\n",
    "<u>**Class Definition:**</u> We create a class that encapsulates all the relevant entities as members. Each member corresponds to an entity such as CEO name, company name, etc., and can include type annotations for better validation and clarity.  \n",
    "\n",
    "<u>**Pydantic Integration:**</u> Utilizing Pydantic, a data validation library, we convert this class into a Pydantic model. This model not only defines the structure of our data but also provides built-in validation features, ensuring that any extracted data adheres to specified formats and types.  \n",
    "\n",
    "<u>**Dynamic Prompting:**</u> The Pydantic model can then be integrated with the prompt sent to the LLM. This allows for a more dynamic interaction where the model can adapt based on the defined structure of entities. If new entities are added or existing ones modified, changes can be made at the class level without needing to rewrite the entire prompt.  \n",
    "\n",
    "<u>**Enhanced Validation:**</u> By leveraging Pydantic's capabilities, we can ensure that any data extracted by the LLM meets our predefined criteria, enhancing data integrity and reliability.  \n",
    "\n",
    "This class-based approach offers greater flexibility and scalability compared to the first method. It allows for easier modifications and expansions as new requirements arise, making it particularly suitable for larger projects or those requiring frequent updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the entities in a class along with the descripiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining all the entities in a class along with the descripiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTaxProfit(BaseModel):\n",
    "    \"This contains information of the company's pre-tax profit in percentage as well as in numbers.\"\n",
    "    pre_tax_profit_percentage: str = Field(description=\"Operating pre-tax profit in percentage.\")\n",
    "    pre_tax_profit_numbers: str = Field(description=\"Operating pre-tax profit in numbers.\")\n",
    "\n",
    "\n",
    "class RevenueGrowth(BaseModel):\n",
    "    \"This contains information of the company's revenue growth.\"\n",
    "    total_revenue_change_transaction_processing: str = Field(description=\"Total revenue change for Transaction Processing sector in percentage.\")\n",
    "    total_revenue_change_data_ai: str = Field(description=\"Total revenue change for Data and AI sector in percentage.\")\n",
    "    total_revenue_change_security: str = Field(description=\"Total revenue change for security sector in percentage.\")\n",
    "    total_revenue_change_automation: str = Field(description=\"Total revenue change for automation sector in percentage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping all the classes into one parent class which is given to pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarningCallReport(BaseModel):\n",
    "    \"This contains information about the company.\"\n",
    "    company_name: str = Field(description=\"The public company name.\")\n",
    "    pre_tax_profit: PreTaxProfit = Field(description=\"Operating pre-tax profit.\")\n",
    "    revenue: RevenueGrowth = Field(description=\"All revenue growth details for all sectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_function = convert_to_openai_function(EarningCallReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar prompt as before, but here, the pydantic function is passed here instead of defining each entity in the prompt text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_prompt_with_pydantic = tokenizer.apply_chat_template(\n",
    "    conversation=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\\\n",
    "- You are AI Entity Extractor. You help extracting entities from the given transcript documents.\n",
    "- Analyze the transcript documents and extract the entities as per the following Pydantic definition:\n",
    "\n",
    "{transcript_function}\n",
    "\n",
    "- Your output should strictly be in a json format.\n",
    "- If any entity is not found, your output should be `data not available`. Do not make up your own entities if it is not present\n",
    "- Only strictly do what is asked to you. Do not give any explanations to your output.\n",
    "\"\"\",\n",
    "    }],\n",
    "    documents=[{\n",
    "        \"doc_id\": doc.metadata[\"doc_id\"],\n",
    "        \"text\": doc.page_content,\n",
    "    } for doc in transcript_content],\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the model to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(entity_prompt_with_pydantic)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_transcript_pydantic = json.loads(response)\n",
    "entities_transcript_pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
