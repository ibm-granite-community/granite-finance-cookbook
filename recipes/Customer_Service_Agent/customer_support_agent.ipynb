{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Customer Service Agent using Granite-3.1-8B-Instruct model and LangChain Framework\n",
    "\n",
    "LLMs possess powerful language understanding and reasoning capabilities. To develop a customer service chatbot or agent, an LLM must be able to interact with external data systems, such as databases, to retrieve real-time order statuses or update customer information.\n",
    "\n",
    "IBM’s Granite-3.1-8B-Instruct is a compact model with robust function-calling capabilities, making it suitable for building agents. This model enables the LLM to interpret customer queries, interact with APIs, and perform real-time data operations on a database through function-calling, ensuring information is accurately updated and maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/ibm-granite-community/utils \"langchain_community<0.3.0\" replicate pydantic pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain_community.llms import Replicate\n",
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import tool\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model object with Granite-3.0-8B-Instruct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Replicate(\n",
    "    model=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
    "    model_kwargs={\"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.invoke(\"What is the meaning of life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database\n",
    "\n",
    "To demonstrate an example of a customer service agent interacting with databases via API, we created synthetic data. Using this data, we set up two SQLite databases: customers and orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Data \n",
    "# Define the data as a list of dictionaries\n",
    "customer_data = [\n",
    "    {\"customer_id\": 1, \"name\": \"Alice Smith\", \"email\": \"alice@example.com\", \"phone\": \"555-1234\"},\n",
    "    {\"customer_id\": 2, \"name\": \"Bob Johnson\", \"email\": \"bob@example.com\", \"phone\": \"555-5678\"},\n",
    "    {\"customer_id\": 3, \"name\": \"Charlie Lee\", \"email\": \"charlie@example.com\", \"phone\": \"555-8765\"},\n",
    "    {\"customer_id\": 4, \"name\": \"Daisy White\", \"email\": \"daisy@example.com\", \"phone\": \"555-2345\"},\n",
    "    {\"customer_id\": 5, \"name\": \"Ethan Clark\", \"email\": \"ethan@example.com\", \"phone\": \"555-6789\"}\n",
    "]\n",
    "order_data = [\n",
    "    {\"order_id\": 1, \"customer_id\": 1, \"product_name\": \"Laptop\", \"order_status\": \"Shipped\", \"order_date\": \"2024-09-20\"},\n",
    "    {\"order_id\": 2, \"customer_id\": 2, \"product_name\": \"Smartphone\", \"order_status\": \"Delivered\", \"order_date\": \"2024-09-18\"},\n",
    "    {\"order_id\": 3, \"customer_id\": 3, \"product_name\": \"Headphones\", \"order_status\": \"Processing\", \"order_date\": \"2024-09-22\"},\n",
    "    {\"order_id\": 4, \"customer_id\": 4, \"product_name\": \"Monitor\", \"order_status\": \"Cancelled\", \"order_date\": \"2024-09-17\"},\n",
    "    {\"order_id\": 5, \"customer_id\": 5, \"product_name\": \"Keyboard\", \"order_status\": \"Delivered\", \"order_date\": \"2024-09-16\"}\n",
    "]\n",
    "\n",
    "df_customer = pd.DataFrame(customer_data)\n",
    "df_order = pd.DataFrame(order_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('example.db')\n",
    "\n",
    "# Write the DataFrame to the SQLite database\n",
    "df_customer.to_sql('customers', conn, if_exists='replace', index=False)\n",
    "df_order.to_sql('orders', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the database to verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM orders\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM customers\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop tools to interact with the database\n",
    "\n",
    "Creating tools for function calling in LLMs involves designing specialized functions that facilitate interaction with external systems, such as databases, APIs, and other applications. By building robust, well-defined function-calling tools, developers enable LLMs to perform specific tasks with precision, like accessing customer data or executing transactions. This approach enhances the LLM’s capability to respond to complex user queries and handle dynamic workflows efficiently.\n",
    "\n",
    "We created two tools: <br>\n",
    "**get_order_by_order_id**: Retrieves the order status based on a given order ID from the orders table. <br>\n",
    "**edit_customer_email_by_customer_name**: Updates a customer's email based on their name in the customers table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_order_by_order_id(order_id: int):\n",
    "    \"\"\"\n",
    "    Retrieve an order_status given the order_id from the orders table.\n",
    "\n",
    "    Parameters:\n",
    "    order_id (int): The ID of the order to retrieve.\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(\"SELECT product_name,order_status FROM orders where order_id= {0}\".format(order_id), conn)\n",
    "    if not df.empty:\n",
    "        return df.iloc[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def edit_customer_email_by_customer_name(customer_name:str, new_email:str):\n",
    "    \"\"\"\n",
    "    Update the email of a customer given their name in the customer table.\n",
    "\n",
    "    Parameters:\n",
    "    customer_name (str): The name of the customer whose email needs to be updated.\n",
    "    new_email (str): The new email address to set.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    update_query = \"UPDATE customers SET email = '{0}' WHERE name = '{1}'\".format(new_email, customer_name)\n",
    "    cursor.execute(update_query)\n",
    "    conn.commit() # Commit the changes to the database\n",
    "    df = pd.read_sql_query(\"SELECT email FROM customers where name= '{0}'\".format(customer_name), conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_order_by_order_id, edit_customer_email_by_customer_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LLM agent using the designated tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish the prompt template\n",
    "\n",
    "We will set up a new prompt template to ask multiple questions. This template is more complex. It is referred to as a [structured chat prompt](https://api.python.langchain.com/en/latest/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html#langchain-agents-structured-chat-base-create-structured-chat-agent) and can be used for creating agents that have multiple tools available. In our case, the tool we are using were defined in previous step. The structured chat prompt will be made up of a `system_prompt`, a `human_prompt` and our `tools`. \n",
    "\n",
    "First, we will set up the `system_prompt`. This prompt instructs the agent to print its \"thought process,\" which involves the agent's subtasks, the tools that were used and the final output. This gives us insight into the agent's function calling. The prompt also instructs the agent to return its responses in JSON Blob format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant. Use the following tools to answer queries:\n",
    "{tools}\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "Follow this format:\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "```\n",
    "Always use tools when possible to gather information before answering.\n",
    "If you can't answer based on the tool outputs and given context, say so.\n",
    "Keep your answers concise and based solely on the provided information.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, we are establishing the `human_prompt`. This prompt tells the agent to display the user input followed by the intermediate steps taken by the agent as part of the `agent_scratchpad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"\"\"{input}\n",
    "{agent_scratchpad}\n",
    "(reminder to always respond in a JSON blob)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we establish the order of our newly defined prompts in the prompt template. We create this new template to feature the `system_prompt` followed by an optional list of messages collected in the agent's memory, if any, and finally, the `human_prompt` which includes both the human input and `agent_scratchpad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's finalize our prompt template by adding the tool names, descriptions and arguments using a [partial prompt template](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/partial/). This allows the agent to access the information pertaining to each tool including the intended use cases and also means we can add and remove tools without altering our entire prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.partial(\n",
    "    tools=render_text_description_and_args(list(tools)),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important feature of AI agents is their memory. Agents are able to store past conversations and past findings in their memory to improve the accuracy and relevance of their responses going forward. In our case, we will use LangChain's `ConversationBufferMemory()` as a means of memory storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can set up a chain with our agent's scratchpad, memory, prompt and the LLM. The AgentExecutor class is used to execute the agent. It takes the agent, its tools, error handling approach, verbose parameter and memory as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "        chat_history=lambda x: memory.chat_memory.messages,\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=chain, tools=tools, handle_parsing_errors=True, verbose=False, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate responses using the customer service agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request the order status from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()\n",
    "agent_executor.invoke({\"input\": \"What is the status of customer's order 4?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request to update a customer's email address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory.clear()\n",
    "agent_executor.invoke({\"input\": \"Update email id of Daisy white to daisywhite.india@gmail.com\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the database has been updated with the new email address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM customers\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
